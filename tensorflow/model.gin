# coding=utf-8
# Copyright 2018 The DisentanglementLib Authors.  All rights reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

model.batch_size = 64
model.random_seed = 0
vae.beta = 1
encoder.num_latent = 10
vae_optimizer.optimizer_fn = @AdamOptimizer
discriminator_optimizer.optimizer_fn=@AdamOptimizer

#no decay
discriminator_optimizer.learning_rate = 0.0001
vae_optimizer.learning_rate = 0.0001
#no decay

#decay
#vae_optimizer.optimizer_fn = @AdamOptimizer
#discriminator_optimizer.optimizer_fn=@AdamOptimizer
#vae_optimizer.learning_rate = @exponential_decay
#discriminator_optimizer.learning_rate = @exponential_decay
#exponential_decay.learning_rate = 0.0001
#exponential_decay.decay_steps = 5000
#exponential_decay.decay_rate = 0.9
#decay

AdamOptimizer.beta1 = 0.9
AdamOptimizer.beta2 = 0.999
AdamOptimizer.epsilon = 1e-08
AdamOptimizer.name = 'Adam'
AdamOptimizer.use_locking = False

# We train for only 20 steps, in practice we train for 300000 steps.
model.training_steps = 300000
model.random_seed=0

encoder.encoder_fn = @conv_encoder
decoder.decoder_fn = @deconv_decoder
discriminator.discriminator_fn = @fc_discriminator
reconstruction_loss.loss_fn = @bernoulli_loss
